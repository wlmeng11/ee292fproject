{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "express-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage import io, color\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-bikini",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "danish-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on tutorial: https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
    "def make_square(img, desired_size=256, fill_color=[255, 255, 255]):\n",
    "    if img.dtype != np.uint8:\n",
    "        print(f'Converting to uint8...')\n",
    "        img = (255*img).astype(np.uint8)\n",
    "        \n",
    "    scale_factor = desired_size/max(img.shape[0], img.shape[1])\n",
    "    resized = cv2.resize(img, (int(scale_factor*img.shape[1]), int(scale_factor*img.shape[0])))\n",
    "    new_size = resized.shape\n",
    "    \n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    \n",
    "    out = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=fill_color)\n",
    "    return out\n",
    "\n",
    "# use float for thresholding, but return uint8 image\n",
    "def binarize(img, threshold=0.5, invert=True):\n",
    "    if img.dtype == np.uint8:\n",
    "        img = img/255.0 # convert to float64\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if len(img.shape) >= 3:\n",
    "        img = color.rgb2gray(img)\n",
    "    \n",
    "    # Threshold\n",
    "    out = np.zeros_like(img)\n",
    "    if invert: # detect dark characters\n",
    "        mask = img < threshold\n",
    "    else: # detect light characters\n",
    "        mask = img > threshold\n",
    "    out[mask] = 1\n",
    "    return (255*out).astype(np.uint8)\n",
    "\n",
    "def preprocess(img, desired_size=256, fill_color=[255, 255, 255], threshold=0.5, invert=True):\n",
    "    img_square = make_square(img, desired_size=desired_size, fill_color=fill_color)\n",
    "    img_bin = binarize(img_square, threshold=threshold, invert=invert)\n",
    "    return img_bin\n",
    "\n",
    "def contour_analysis(img, n=2, trim_points=10, bins=20, verbose=False):\n",
    "    # Find all contours\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    if verbose:\n",
    "        print(f'# of contours: {len(contours)}')\n",
    "        print('# of points in each contour:')\n",
    "        for cnt in contours:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "\n",
    "    # Remove contours with too few points\n",
    "    contours_trimmed = [cnt for cnt in contours if len(cnt) > trim_points]\n",
    "    if verbose:\n",
    "        print(f'Trimming contours with fewer than {trim_points} points...')\n",
    "        print(f'# of remaining contours: {len(contours_trimmed)}')\n",
    "        for cnt in contours_trimmed:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "\n",
    "    # Create dashed contours by keeping every nth point\n",
    "    assert(n>=2)\n",
    "    contours_dashed = [cnt[1::n] for cnt in contours_trimmed]\n",
    "    if verbose:\n",
    "        print(f'Taking every {n}th point to get dashed contour...')\n",
    "        for cnt in contours_dashed:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "            \n",
    "    # Find angles between adjacent points in the contour\n",
    "    thetaseq = []\n",
    "    for i, cnt in enumerate(contours_dashed):\n",
    "        for j, point in enumerate(cnt):\n",
    "            if j == 0:\n",
    "                prevx, prevy = point[0]\n",
    "            else:\n",
    "                x, y = point[0]\n",
    "                thetaseq.append(np.arctan2(y-prevy, x-prevx))\n",
    "                prevx = x\n",
    "                prevy = y\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'# thetas: {len(thetaseq)}')\n",
    "        print(f'max theta: {max(thetaseq)}')\n",
    "        print(f'min theta: {min(thetaseq)}')\n",
    "\n",
    "    hist =  np.histogram(thetaseq, bins=bins, range=(-np.pi, np.pi))\n",
    "    return hist\n",
    "\n",
    "def plot_angles(hist, ax=None, title='Distribution of angles'):\n",
    "    r, theta = hist\n",
    "    r = np.append(r, 0) # append zero to correspond to the last angle\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(4, 4), dpi=300)\n",
    "\n",
    "    ax.plot(theta, r)\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_title(title, va='bottom')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_mu_and_K(X, title='', filename='mu+K.png'):\n",
    "    mu = np.mean(X, axis=1)\n",
    "    K = np.cov(X)\n",
    "    bins = len(mu)\n",
    "    theta = np.linspace(-np.pi, np.pi, bins+1)\n",
    " \n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    ax1 = plt.subplot(121, projection='polar')\n",
    "    ax2 = plt.subplot(122)\n",
    "    plot_angles([mu, theta], ax=ax1, title='Mean vector Î¼')\n",
    "    fig.colorbar(ax2.imshow(K))\n",
    "    ax2.set_title('Covariance matrix K')\n",
    "    plt.suptitle(title, fontsize='xx-large')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "def analyze_images_in_path(path='', bins=20, verbose=False):\n",
    "    filenames = os.listdir(path)\n",
    "    filenames.sort()\n",
    "    if verbose:\n",
    "        print(filenames)\n",
    "    \n",
    "    X = np.zeros((bins, len(filenames)))\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = io.imread(path + filename)\n",
    "        counts, theta = contour_analysis(preprocess(img), bins=bins)\n",
    "        # divide counts by total counts to get Probability Mass Function (PMF)\n",
    "        probs = counts / counts.sum()\n",
    "        X[:, i] = probs\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-illustration",
   "metadata": {},
   "source": [
    "# Mi Fu's *Poem Written In a Boat on the Wu River*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "waiting-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.png', '002.png', '003.png', '004.png', '005.png', '006.png', '007.png', '008.png', '009.png', '010.png', '011.png', '012.png', '013.png', '014.png', '015.png', '016.png', '017.png', '018.png', '019.png', '020.png', '021.png', '022.png', '023.png', '024.png', '025.png', '026.png', '027.png', '028.png', '029.png', '030.png', '031.png', '032.png', '033.png', '034.png', '035.png', '036.png', '037.png', '038.png', '039.png', '040.png', '041.png', '042.png', '043.png', '044.png', '045.png', '046.png', '047.png', '048.png', '049.png', '050.png', '051.png', '052.png', '053.png', '054.png', '055.png', '056.png', '057.png', '058.png', '059.png', '060.png', '061.png', '062.png', '063.png', '064.png', '065.png', '066.png', '067.png', '068.png', '069.png', '070.png', '071.png', '072.png', '073.png', '074.png', '075.png', '076.png', '077.png', '078.png', '079.png', '080.png', '081.png', '082.png', '083.png', '084.png', '085.png', '086.png', '087.png', '088.png', '089.png', '090.png', '091.png']\n"
     ]
    }
   ],
   "source": [
    "path = 'Extracted Characters/Mi Fu - Poem Written in a Boat on the Wu River/'\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort()\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "included-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 20\n",
    "X = np.zeros((bins, len(filenames)))\n",
    "for i, filename in enumerate(filenames):\n",
    "    img = io.imread(path + filename)\n",
    "    counts, theta = contour_analysis(preprocess(img), bins=bins)\n",
    "    # divide counts by total counts to get Probability Mass Function (PMF)\n",
    "    probs = counts / counts.sum()\n",
    "    X[:, i] = probs\n",
    "    \n",
    "plot_mu_and_K(X, title=f'Wu River ({len(filenames)} images)', path='TestWuRiver/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "banner-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call the function that automates this\n",
    "X = analyze_images_in_path(path)\n",
    "plot_mu_and_K(X, title=f'Wu River ({X.shape[1]} images)', filename='TestWuRiver/mu+K.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-thirty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ee367-hw)",
   "language": "python",
   "name": "ee367-hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
