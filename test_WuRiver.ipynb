{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "driving-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage import io, color\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-array",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adopted-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on tutorial: https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
    "def make_square(img, desired_size=256, fill_color=[255, 255, 255]):\n",
    "    if img.dtype != np.uint8:\n",
    "        print(f'Converting to uint8...')\n",
    "        img = (255*img).astype(np.uint8)\n",
    "        \n",
    "    scale_factor = desired_size/max(img.shape[0], img.shape[1])\n",
    "    resized = cv2.resize(img, (int(scale_factor*img.shape[1]), int(scale_factor*img.shape[0])))\n",
    "    new_size = resized.shape\n",
    "    \n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    \n",
    "    out = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=fill_color)\n",
    "    return out\n",
    "\n",
    "# use float for thresholding, but return uint8 image\n",
    "def binarize(img, threshold=0.5, invert=True):\n",
    "    if img.dtype == np.uint8:\n",
    "        img = img/255.0 # convert to float64\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if len(img.shape) >= 3:\n",
    "        img = color.rgb2gray(img)\n",
    "    \n",
    "    # Threshold\n",
    "    out = np.zeros_like(img)\n",
    "    if invert: # detect dark characters\n",
    "        mask = img < threshold\n",
    "    else: # detect light characters\n",
    "        mask = img > threshold\n",
    "    out[mask] = 1\n",
    "    return (255*out).astype(np.uint8)\n",
    "\n",
    "def preprocess(img, desired_size=256, fill_color=[255, 255, 255], threshold=0.5, invert=True):\n",
    "    img_square = make_square(img, desired_size=desired_size, fill_color=fill_color)\n",
    "    img_bin = binarize(img_square, threshold=threshold, invert=invert)\n",
    "    return img_bin\n",
    "\n",
    "def contour_analysis(img, n=2, trim_points=10, bins=20, verbose=False):\n",
    "    # Find all contours\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    if verbose:\n",
    "        print(f'# of contours: {len(contours)}')\n",
    "        print('# of points in each contour:')\n",
    "        for cnt in contours:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "\n",
    "    # Remove contours with too few points\n",
    "    contours_trimmed = [cnt for cnt in contours if len(cnt) > trim_points]\n",
    "    if verbose:\n",
    "        print(f'Trimming contours with fewer than {trim_points} points...')\n",
    "        print(f'# of remaining contours: {len(contours_trimmed)}')\n",
    "        for cnt in contours_trimmed:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "\n",
    "    # Create dashed contours by keeping every nth point\n",
    "    assert(n>=2)\n",
    "    contours_dashed = [cnt[1::n] for cnt in contours_trimmed]\n",
    "    if verbose:\n",
    "        print(f'Taking every {n}th point to get dashed contour...')\n",
    "        for cnt in contours_dashed:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "            \n",
    "    # Find angles between adjacent points in the contour\n",
    "    thetaseq = []\n",
    "    for i, cnt in enumerate(contours_dashed):\n",
    "        for j, point in enumerate(cnt):\n",
    "            if j == 0:\n",
    "                prevx, prevy = point[0]\n",
    "            else:\n",
    "                x, y = point[0]\n",
    "                thetaseq.append(np.arctan2(y-prevy, x-prevx))\n",
    "                prevx = x\n",
    "                prevy = y\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'# thetas: {len(thetaseq)}')\n",
    "        print(f'max theta: {max(thetaseq)}')\n",
    "        print(f'min theta: {min(thetaseq)}')\n",
    "\n",
    "    hist =  np.histogram(thetaseq, bins=bins, range=(-np.pi, np.pi))\n",
    "    return hist\n",
    "\n",
    "def plot_angles(hist, ax=None, title='Distribution of angles'):\n",
    "    r, theta = hist\n",
    "    r = np.append(r, r[0]) # append 0th element to end cuz -pi and pi are the same angle\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(4, 4), dpi=300)\n",
    "\n",
    "    ax.plot(theta, r)\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_title(title, va='bottom')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_mu_and_K(X, title='', filename='mu+K.png'):\n",
    "    mu = np.mean(X, axis=1)\n",
    "    K = np.cov(X)\n",
    "    bins = len(mu)\n",
    "    theta = np.linspace(-np.pi, np.pi, bins+1)\n",
    " \n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    ax1 = plt.subplot(121, projection='polar')\n",
    "    ax2 = plt.subplot(122)\n",
    "    plot_angles([mu, theta], ax=ax1, title='Mean vector Î¼')\n",
    "    fig.colorbar(ax2.imshow(K))\n",
    "    ax2.set_title('Covariance matrix K')\n",
    "    plt.suptitle(title, fontsize='xx-large')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "def analyze_images_in_path(path='', bins=20, verbose=False):\n",
    "    filenames = os.listdir(path)\n",
    "    filenames.sort()\n",
    "    if verbose:\n",
    "        print(filenames)\n",
    "    \n",
    "    X = np.zeros((bins, len(filenames)))\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = io.imread(path + filename)\n",
    "        counts, theta = contour_analysis(preprocess(img), bins=bins)\n",
    "        # divide counts by total counts to get Probability Mass Function (PMF)\n",
    "        probs = counts / counts.sum()\n",
    "        X[:, i] = probs\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-nudist",
   "metadata": {},
   "source": [
    "# Mi Fu's *Poem Written In a Boat on the Wu River*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "opposed-powder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.png', '002.png', '003.png', '004.png', '005.png', '006.png', '007.png', '008.png', '009.png', '010.png', '011.png', '012.png', '013.png', '014.png', '015.png', '016.png', '017.png', '018.png', '019.png', '020.png', '021.png', '022.png', '023.png', '024.png', '025.png', '026.png', '027.png', '028.png', '029.png', '030.png', '031.png', '032.png', '033.png', '034.png', '035.png', '036.png', '037.png', '038.png', '039.png', '040.png', '041.png', '042.png', '043.png', '044.png', '045.png', '046.png', '047.png', '048.png', '049.png', '050.png', '051.png', '052.png', '053.png', '054.png', '055.png', '056.png', '057.png', '058.png', '059.png', '060.png', '061.png', '062.png', '063.png', '064.png', '065.png', '066.png', '067.png', '068.png', '069.png', '070.png', '071.png', '072.png', '073.png', '074.png', '075.png', '076.png', '077.png', '078.png', '079.png', '080.png', '081.png', '082.png', '083.png', '084.png', '085.png', '086.png', '087.png', '088.png', '089.png', '090.png', '091.png']\n"
     ]
    }
   ],
   "source": [
    "path = 'Extracted Characters/Mi Fu - Poem Written in a Boat on the Wu River/'\n",
    "filenames = os.listdir(path)\n",
    "filenames.sort()\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "responsible-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = analyze_images_in_path(path)\n",
    "plot_mu_and_K(X, title=f'Wu River ({X.shape[1]} images)', filename='TestWuRiver/mu+K.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-rainbow",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "greenhouse-celtic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.46376558 0.18567444]\n",
      "Singular values: [0.64595277 0.40872158]\n",
      "# of datapoints: 91\n",
      "Principal Components of each datapoint:\n",
      "[[ 0.00036497 -0.04055316]\n",
      " [-0.04857066 -0.07094967]\n",
      " [ 0.06122655  0.04654032]\n",
      " [-0.01613446 -0.00603782]\n",
      " [ 0.02814406 -0.01462888]\n",
      " [ 0.00671194 -0.00175597]\n",
      " [ 0.01776733  0.03306314]\n",
      " [ 0.03402     0.00555434]\n",
      " [-0.03777442 -0.049431  ]\n",
      " [-0.05745886 -0.04579842]\n",
      " [-0.00853481 -0.04679862]\n",
      " [-0.01135655 -0.00698931]\n",
      " [-0.02071141  0.00842589]\n",
      " [ 0.01274043 -0.0583408 ]\n",
      " [ 0.08382157  0.03102172]\n",
      " [-0.02297599  0.01905669]\n",
      " [ 0.10739135  0.03128132]\n",
      " [-0.05256259  0.00947863]\n",
      " [ 0.00198506 -0.08034348]\n",
      " [-0.04629028  0.01712935]\n",
      " [-0.02251515 -0.0095294 ]\n",
      " [-0.00461233 -0.00882975]\n",
      " [ 0.01980275  0.02980875]\n",
      " [-0.02633659 -0.0312785 ]\n",
      " [ 0.00528308  0.02810656]\n",
      " [ 0.01261909 -0.02890035]\n",
      " [-0.02613037  0.00528459]\n",
      " [ 0.06926955 -0.00316414]\n",
      " [-0.04079143 -0.00750503]\n",
      " [-0.02019476 -0.04851468]\n",
      " [-0.02102922  0.00042207]\n",
      " [-0.03282467 -0.01954578]\n",
      " [ 0.00114016 -0.01408372]\n",
      " [-0.03612674 -0.07861047]\n",
      " [-0.04191981  0.1137099 ]\n",
      " [-0.01027938  0.01038752]\n",
      " [ 0.06838154  0.00281642]\n",
      " [ 0.05751395 -0.02492435]\n",
      " [ 0.05006564 -0.04385745]\n",
      " [ 0.02714702  0.02237089]\n",
      " [ 0.00743597 -0.03516942]\n",
      " [ 0.02122093  0.0481397 ]\n",
      " [-0.02674342  0.02259114]\n",
      " [-0.11627673 -0.0445204 ]\n",
      " [ 0.14756285 -0.00994728]\n",
      " [ 0.03723991 -0.02735539]\n",
      " [ 0.10261138 -0.04172916]\n",
      " [-0.07526478  0.02993773]\n",
      " [-0.06880545  0.06969791]\n",
      " [-0.0356955   0.02209974]\n",
      " [ 0.0263826  -0.03728009]\n",
      " [-0.10513997 -0.05903729]\n",
      " [-0.04178605  0.034805  ]\n",
      " [ 0.03067633  0.08238439]\n",
      " [ 0.00478153 -0.01548877]\n",
      " [ 0.08591645 -0.046227  ]\n",
      " [-0.12224827  0.03558798]\n",
      " [-0.09262674  0.08021686]\n",
      " [ 0.04236324  0.02712873]\n",
      " [ 0.07267688  0.00140991]\n",
      " [-0.03467001 -0.03422814]\n",
      " [ 0.01463398 -0.02914405]\n",
      " [ 0.07040397  0.04669152]\n",
      " [ 0.07986894  0.05097841]\n",
      " [ 0.01275965 -0.04915246]\n",
      " [-0.04613613  0.05912617]\n",
      " [-0.09462118  0.00248278]\n",
      " [-0.04215467  0.06894821]\n",
      " [ 0.05764012  0.03715256]\n",
      " [-0.03558009  0.00720354]\n",
      " [ 0.33323815 -0.07603338]\n",
      " [-0.04893545 -0.05947097]\n",
      " [ 0.05066196  0.01730223]\n",
      " [-0.01873652 -0.00877428]\n",
      " [ 0.03080423 -0.02587793]\n",
      " [ 0.0144918   0.06659497]\n",
      " [-0.03982649  0.00121721]\n",
      " [-0.01840615 -0.03771815]\n",
      " [ 0.03467702 -0.0416603 ]\n",
      " [ 0.06683024 -0.01745085]\n",
      " [ 0.03969235 -0.00685914]\n",
      " [-0.09180208 -0.01020319]\n",
      " [-0.07876723 -0.03375205]\n",
      " [-0.00392738  0.0955278 ]\n",
      " [ 0.01493584  0.10383417]\n",
      " [-0.07181534 -0.01699606]\n",
      " [ 0.08647546  0.05137527]\n",
      " [-0.17359093 -0.06907525]\n",
      " [-0.13553269  0.01051043]\n",
      " [-0.01615545  0.03958882]\n",
      " [ 0.08899732  0.04653042]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(np.transpose(X))\n",
    "print(f'Explained variance ratio: {pca.explained_variance_ratio_}')\n",
    "print(f'Singular values: {pca.singular_values_}')\n",
    "components = pca.fit_transform(np.transpose(X))\n",
    "print(f'# of datapoints: {len(components)}')\n",
    "print(f'Principal Components of each datapoint:\\n{components}')\n",
    "plt.scatter(components[:, 0], components[:, 1], label='Wu River')\n",
    "plt.title('PCA')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend()\n",
    "plt.savefig('TestWuRiver/PCA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-discretion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ee367-hw)",
   "language": "python",
   "name": "ee367-hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
