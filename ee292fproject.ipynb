{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57399a45",
   "metadata": {},
   "source": [
    "# EE 292F Project\n",
    "William Meng  \n",
    "EE 292F: Image Processing of Fine Arts  \n",
    "June 2, 2021  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from skimage import io, color\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import ndimage\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-yellow",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on tutorial: https://jdhao.github.io/2017/11/06/resize-image-to-square-with-padding/\n",
    "def make_square(img, desired_size=256, fill_color=[255, 255, 255]):\n",
    "    if img.dtype != np.uint8:\n",
    "        print(f'Converting to uint8...')\n",
    "        img = (255*img).astype(np.uint8)\n",
    "        \n",
    "    scale_factor = desired_size/max(img.shape[0], img.shape[1])\n",
    "    resized = cv2.resize(img, (int(scale_factor*img.shape[1]), int(scale_factor*img.shape[0])))\n",
    "    new_size = resized.shape\n",
    "    \n",
    "    delta_w = desired_size - new_size[1]\n",
    "    delta_h = desired_size - new_size[0]\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "    \n",
    "    out = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=fill_color)\n",
    "    return out\n",
    "\n",
    "# use float for thresholding, but return uint8 image\n",
    "def binarize(img, threshold=0.5, invert=True):\n",
    "    if img.dtype == np.uint8:\n",
    "        img = img/255.0 # convert to float64\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if len(img.shape) >= 3:\n",
    "        img = color.rgb2gray(img)\n",
    "    \n",
    "    # Threshold\n",
    "    out = np.zeros_like(img)\n",
    "    if invert: # detect dark characters\n",
    "        mask = img < threshold\n",
    "    else: # detect light characters\n",
    "        mask = img > threshold\n",
    "\n",
    "    out[mask] = 1\n",
    "    return (255*out).astype(np.uint8)\n",
    "\n",
    "def preprocess(img, desired_size=256, threshold=0.5, invert=True):\n",
    "    if invert: # detect black character on white background\n",
    "        fill_color = [255, 255, 255]\n",
    "    else: # detect white character on black background\n",
    "        fill_color = [0, 0, 0]\n",
    "\n",
    "    img_square = make_square(img, desired_size=desired_size, fill_color=fill_color)\n",
    "    img_bin = binarize(img_square, threshold=threshold, invert=invert)\n",
    "    return img_bin\n",
    "\n",
    "def feature_analysis(img, n=4, trim_points=10, bins=20, verbose=False):\n",
    "    # Find all contours\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    if verbose:\n",
    "        print(f'# of contours: {len(contours)}')\n",
    "        print('# of points in each contour:')\n",
    "        for cnt in contours:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "\n",
    "    # Remove contours with too few points\n",
    "    contours_trimmed = [cnt for cnt in contours if len(cnt) > trim_points]\n",
    "    if verbose:\n",
    "        print(f'Trimming contours with fewer than {trim_points} points...')\n",
    "        print(f'# of remaining contours: {len(contours_trimmed)}')\n",
    "        for cnt in contours_trimmed:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "\n",
    "    # Create dashed contours by keeping every nth point\n",
    "    assert(n>=2)\n",
    "    contours_dashed = [cnt[1::n] for cnt in contours_trimmed]\n",
    "    if verbose:\n",
    "        print(f'Taking every {n}th point to get dashed contour...')\n",
    "        for cnt in contours_dashed:\n",
    "            print(f'\\t{len(cnt)} points')\n",
    "            \n",
    "    # Find angles between adjacent points in the contour\n",
    "    thetaseq = []\n",
    "    for i, cnt in enumerate(contours_dashed):\n",
    "        for j, point in enumerate(cnt):\n",
    "            if j == 0:\n",
    "                prevx, prevy = point[0]\n",
    "            else:\n",
    "                x, y = point[0]\n",
    "                thetaseq.append(np.arctan2(y-prevy, x-prevx))\n",
    "                prevx = x\n",
    "                prevy = y\n",
    "    \n",
    "    dthetaseq = np.diff(thetaseq)\n",
    "    hist_theta = np.histogram(thetaseq, bins=bins, range=(-np.pi, np.pi), density=True)\n",
    "    hist_dtheta =  np.histogram(dthetaseq, bins=bins, range=(-np.pi, np.pi), density=True)\n",
    "    density_theta, theta = hist_theta\n",
    "    density_dtheta, dtheta = hist_dtheta\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'# thetas: {len(thetaseq)}')\n",
    "        print(f'max theta: {max(thetaseq)}')\n",
    "        print(f'min theta: {min(thetaseq)}')\n",
    "        print(f'len(thetaseq): {len(thetaseq)}')\n",
    "        print(f'dthetaseq.shape: {dthetaseq.shape}')\n",
    "        print(f'density_theta.shape: {density_theta.shape}')\n",
    "        print(f'density_dtheta.shape: {density_dtheta.shape}')\n",
    "\n",
    "    rows, cols = img.shape\n",
    "    X, Y = np.meshgrid(np.linspace(0, 1, cols), np.linspace(0, 1, rows))\n",
    "    assert(X.shape == Y.shape == img.shape)\n",
    "    M = np.sum(img)\n",
    "    M_norm = M/(255*rows*cols)\n",
    "    EX = np.sum(X*img)/M\n",
    "    EY = np.sum(Y*img)/M\n",
    "    DX = np.sum(X**2 * img)/M - EX**2\n",
    "    DY = np.sum(Y**2 * img)/M - EY**2\n",
    "    covXY = np.sum(X*Y*img)/M - EX*EY\n",
    "    \n",
    "    features = np.hstack((density_theta, density_dtheta, M_norm, EX, EY, DX, DY, covXY))\n",
    "    #features = np.hstack((density_theta, density_dtheta, M_norm, DX, DY, covXY))\n",
    "    if verbose:\n",
    "        print(f'features.shape: {features.shape}')\n",
    "        print(f'M = {M}')\n",
    "        print(f'M_norm = {M_norm}')\n",
    "        print(f'EX = {EX}')\n",
    "        print(f'EY = {EY}')\n",
    "        print(f'DX = {DX}')\n",
    "        print(f'DY = {DY}')\n",
    "        print(f'covXY = {covXY}')\n",
    "    return features\n",
    "\n",
    "def plot_angles(hist, ax=None, title='Distribution of angles', label=''):\n",
    "    r, theta = hist\n",
    "    bins = len(r)\n",
    "    #theta += np.pi/bins\n",
    "    r = np.append(r, r[0]) # append 0th element to end cuz -pi and pi are the same angle\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, figsize=(4, 4), dpi=300)\n",
    "\n",
    "    ax.plot(theta, r, label=label)\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax.set_title(title, va='bottom')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plot_hists(X, title='', filename='hists.png'):\n",
    "    bins = 20\n",
    "    theta = np.linspace(-np.pi, np.pi, bins+1)\n",
    "    X_theta = X[0:bins]\n",
    "    X_dtheta = X[bins:2*bins]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    ax1 = plt.subplot(121, projection='polar')\n",
    "    ax2 = plt.subplot(122, projection='polar')\n",
    "    plot_angles([X_theta, theta], ax=ax1, title='Contour Angles')\n",
    "    plot_angles([X_dtheta, theta], ax=ax2, title='Contour Curvatures')\n",
    "    plt.suptitle(title, fontsize='xx-large')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "def feature_analysis_in_path(path='', bins=20, invert=True, verbose=False):\n",
    "    filenames = os.listdir(path)\n",
    "    filenames.sort()\n",
    "    if verbose:\n",
    "        print(filenames)\n",
    "    \n",
    "    num_features = 2*bins + 6\n",
    "    #num_features = 2*bins + 4\n",
    "    X = np.zeros((num_features, len(filenames)))\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = io.imread(path + filename)\n",
    "        features = feature_analysis(preprocess(img, invert=invert), bins=bins)\n",
    "        X[:, i] = features.T\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-trash",
   "metadata": {},
   "source": [
    "# PCA with 46 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['Extracted Characters/Mi Fu - Poem Written in a Boat on the Wu River/',\n",
    "         'Extracted Characters/Emperor Huizong - Finches and bamboo/',\n",
    "         'Extracted Characters/Su Shi - Inscription of Hanshi/',\n",
    "         'Extracted Characters/WangXiZhi - On the Seventeenth Day/',\n",
    "         'Extracted Characters/Mi Fu - On Cursive Calligraphy/']\n",
    "label_list = ['Mi Fu (Wu River)',\n",
    "             'Huizong',\n",
    "             'Su Shi',\n",
    "             'WangXiZhi',\n",
    "             'Mi Fu (On Cursive Calligraphy)']\n",
    "invert_list = [True,\n",
    "              True,\n",
    "              True,\n",
    "              False,\n",
    "              True]\n",
    "\n",
    "# Construct labeled dataset of contour angle histograms\n",
    "X_list = []\n",
    "labels = []\n",
    "for i, path in enumerate(paths):\n",
    "    label = label_list[i]\n",
    "    invert = invert_list[i]\n",
    "    if invert:\n",
    "        X = feature_analysis_in_path(path, invert=True)\n",
    "    else:\n",
    "        X = feature_analysis_in_path(path, invert=False)\n",
    "    X_list.append(X)\n",
    "    labels += [label] * X.shape[1]\n",
    "    mu = np.mean(X, axis=1)\n",
    "    plot_hists(mu, title=label, filename=f'Results/hists_{label.replace(\" \", \"\")}.png')\n",
    "    \n",
    "X_total =  np.vstack([X.T for X in X_list])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(X_total)\n",
    "print(f'# of datapoints: {len(components)}')\n",
    "print(f'len(labels) = {len(labels)}')\n",
    "assert(len(labels) == len(components))\n",
    "total_var = pca.explained_variance_ratio_.sum() * 100\n",
    "print('Total explained variance = {:0.2f}%'.format(total_var))\n",
    "\n",
    "# Plot results with Plotly\n",
    "fig = px.scatter(components, x=0, y=1, color=labels)\n",
    "fig.update_layout(\n",
    "    title=\"PCA\",\n",
    "    xaxis_title=\"PC 1\",\n",
    "    yaxis_title=\"PC 2\",\n",
    "    legend_title=\"Class\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image('Results/PCA_Plotly_46features.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 5 contour angle histograms\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax1 = plt.subplot(511, projection='polar')\n",
    "ax2 = plt.subplot(512, projection='polar')\n",
    "ax3 = plt.subplot(513, projection='polar')\n",
    "ax4 = plt.subplot(514, projection='polar')\n",
    "ax5 = plt.subplot(515, projection='polar')\n",
    "axes = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "bins = 20\n",
    "theta = np.linspace(-np.pi, np.pi, bins+1)\n",
    "for i, X in enumerate(X_list):\n",
    "    label = label_list[i]\n",
    "    mu = np.mean(X, axis=1)\n",
    "    plot_angles([mu[0:bins], theta], ax=axes[i], title=label)\n",
    "    #plot_angles([mu[bins:2*bins], theta], ax=axes[i], title=label) # curvature\n",
    "plt.suptitle('Contour Angle Statistics', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Results/ContourAngleStatistics.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 5 curvature histograms\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax1 = plt.subplot(511, projection='polar')\n",
    "ax2 = plt.subplot(512, projection='polar')\n",
    "ax3 = plt.subplot(513, projection='polar')\n",
    "ax4 = plt.subplot(514, projection='polar')\n",
    "ax5 = plt.subplot(515, projection='polar')\n",
    "axes = [ax1, ax2, ax3, ax4, ax5]\n",
    "\n",
    "bins = 20\n",
    "theta = np.linspace(-np.pi, np.pi, bins+1)\n",
    "for i, X in enumerate(X_list):\n",
    "    label = label_list[i]\n",
    "    mu = np.mean(X, axis=1)\n",
    "    plot_angles([mu[bins:2*bins], theta], ax=axes[i], title=label) # curvature\n",
    "plt.suptitle('Curvature Statistics', fontsize='xx-large')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Results/CurvatureStatistics.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the Principal Components\n",
    "pca.fit(X_total)\n",
    "PC1, PC2 = pca.components_\n",
    "print(f'PC 1 = {PC1}')\n",
    "print(f'PC 2 = {PC2}')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(PC1, label='PC 1')\n",
    "plt.plot(PC2, label='PC 2')\n",
    "plt.legend()\n",
    "plt.title('Principal Components')\n",
    "plt.savefig('Results/PrincipalComponents.png')\n",
    "\n",
    "\n",
    "bins = 20\n",
    "theta = np.linspace(-np.pi, np.pi, bins+1)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = plt.subplot(121, projection='polar')\n",
    "ax2 = plt.subplot(122, projection='polar')\n",
    "plot_angles([PC1[0:bins], theta], ax=ax1, title='Contour Angles')\n",
    "plot_angles([PC2[0:bins], theta], ax=ax1, title='Contour Angles')\n",
    "plot_angles([PC1[bins:2*bins], theta], ax=ax2, title='Contour Curvatures')\n",
    "plot_angles([PC2[bins:2*bins], theta], ax=ax2, title='Contour Curvatures')\n",
    "plt.suptitle('Principal Components', fontsize='xx-large')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Results/PC_hists.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-caution",
   "metadata": {},
   "source": [
    "# Classification\n",
    "First, split labeled data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_total, labels, test_size=0.33, random_state=42)\n",
    "print(f'X_total.shape: {X_total.shape}')\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'len(y_train): {len(y_train)}')\n",
    "print(f'len(y_test): {len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-medline",
   "metadata": {},
   "source": [
    "Now let's run a bunch of classifiers based on this tutorial: https://www.kaggle.com/jeffd23/10-classifier-showdown-in-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-charles",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    #QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.xlim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Results/ClassifierAccuracy.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n",
    "\n",
    "plt.xlabel('Log Loss')\n",
    "plt.title('Classifier Log Loss')\n",
    "plt.xlim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.savefig('Results/ClassifierLogLoss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ee367-hw)",
   "language": "python",
   "name": "ee367-hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
